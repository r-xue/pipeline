@ARTICLE{2023PASP..135g4501H,
       author = {{Hunter}, Todd R. and {Indebetouw}, Remy and {Brogan}, Crystal L. and {Berry}, Kristin and {Chang}, Chin-Shin and {Francke}, Harold and {Geers}, Vincent C. and {G{\'o}mez}, Laura and {Hibbard}, John E. and {Humphreys}, Elizabeth M. and {Kent}, Brian R. and {Kepley}, Amanda A. and {Kunneriath}, Devaky and {Lipnicky}, Andrew and {Loomis}, Ryan A. and {Mason}, Brian S. and {Masters}, Joseph S. and {Maud}, Luke T. and {Muders}, Dirk and {Sabater}, Jose and {Sugimoto}, Kanako and {Sz{\H{u}}cs}, L{\'a}szl{\'o} and {Vasiliev}, Eugene and {Videla}, Liza and {Villard}, Eric and {Williams}, Stewart J. and {Xue}, Rui and {Yoon}, Ilsang},
        title = "{The ALMA Interferometric Pipeline Heuristics}",
      journal = {\pasp},
     keywords = {Submillimeter astronomy, Millimeter astronomy, Calibration, Astronomy software, Aperture synthesis, Heterodyne interferometry, Astrophysics - Instrumentation and Methods for Astrophysics},
         year = 2023,
        month = jul,
       volume = {135},
       number = {1049},
          eid = {074501},
        pages = {074501},
     abstract = "{We describe the calibration and imaging heuristics developed and
        deployed in the Atacama Large Millimeter/submillimeter Array
        (ALMA) interferometric data processing pipeline, as of ALMA
        Cycle 9 operations. The pipeline software framework is written
        in Python, with each data reduction stage layered on top of
        tasks and toolkit functions provided by the Common Astronomy
        Software Applications package. This framework supports a variety
        of tasks for observatory operations, including science data
        quality assurance, observing mode commissioning, and user
        reprocessing. It supports ALMA and Very Large Array
        interferometric data along with ALMA and NRO 45 m single dish
        data, via different stages and heuristics. In addition to
        producing calibration tables, calibrated measurement sets, and
        cleaned images, the pipeline creates a WebLog which serves as
        the primary interface for verifying the quality assurance of the
        data by the observatory and for examining the contents of the
        data by the user. Following the adoption of the pipeline by ALMA
        Operations in 2014, the heuristics have been refined through
        annual prioritized development cycles, culminating in a new
        pipeline release aligned with the start of each ALMA Cycle of
        observations. Initial development focused on basic calibration
        and flagging heuristics (Cycles 2-3), followed by imaging
        heuristics (Cycles 4-5). Further refinement of the flagging and
        imaging heuristics, including the introduction of parallel
        processing, proceeded for Cycles 6-7. In the 2020 release, the
        algorithm to identify channels to use for continuum subtraction
        and imaging was substantially improved by the addition of a
        moment difference analysis. A spectral renormalization stage was
        added for the 2021 release (Cycle 8) to correct high spectral
        resolution visibility data acquired on targets exhibiting strong
        celestial line emission in their autocorrelation spectra. The
        calibration heuristics used in the low signal-to-noise regime
        were improved for the 2022 release (Cycle 9). In the two most
        recent Cycles, 97\% of ALMA data sets were calibrated and imaged
        with the pipeline, ensuring long-term automated reproducibility
        of results. We conclude with a brief description of plans for
        future additions, including a self-calibration stage, support
        for multi-configuration imaging, and complete calibration and
        imaging of full polarization data.}",
          doi = {10.1088/1538-3873/ace216},
archivePrefix = {arXiv},
       eprint = {2306.07420},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2023PASP..135g4501H},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2023AAS...24110527H,
       author = {{Hunter}, Todd and {ALMA Pipeline Working Group}},
        title = "{Heuristics of the ALMA Interferometric Calibration and Imaging Pipeline}",
    booktitle = {American Astronomical Society Meeting Abstracts},
         year = 2023,
       series = {American Astronomical Society Meeting Abstracts},
       volume = {55},
        month = jan,
          eid = {105.27},
        pages = {105.27},
     abstract = "{We describe the calibration and imaging heuristics developed, tested,
        and deployed in the Atacama Large Millimeter/sub-millimeter
        Array (ALMA) interferometric data processing pipeline as of ALMA
        Cycle 9 operations. The pipeline software framework (Davis et
        al. 2015) is written in Python, with each data reduction stage
        layered upon tasks and toolkit functions provided by the Common
        Astronomy Software Applications (CASA) package
        (arXiv:2210.02276). This framework supports observatory
        operations, reprocessing, commissioning, testing, and user
        desktop reprocessing. In addition to producing calibration
        tables, calibrated measurement sets, and cleaned images, the
        pipeline creates a ``weblog'' which serves as the primary
        interface in verifying the quality assurance (QA) of each
        calibration and imaging stage. Since the first use of the
        pipeline in October 2014, refinement of the pipeline heuristics
        has occurred on an annual prioritized development cycle,
        culminating in a new pipeline release aligned with the start of
        each cycle of observations. Initial development focused on basic
        calibration and flagging heuristics (Cycle 2-3), followed by
        imaging heuristics (Cycle 4-5). Further refinement of the
        flagging and imaging heuristics proceeded for Cycles 6-7. A data
        renormalization stage was added for Cycle 8 to correct ALMA
        visibility data on targets exhibiting strong line emission in
        their autocorrelation spectra. The calibration heuristics in the
        limit of low signal to noise ratio were improved for Cycle 9,
        along with the presentation of QA scores. Refinements of the
        algorithm to identify channels for continuum imaging has been
        ongoing since Cycle 4. After summarizing the heuristics within
        the current pipeline release, we briefly describe plans for
        future improvements, including adding a self-calibration stage,
        adding support for group imaging, and completing the calibration
        and imaging of full polarization data. The pipeline is developed
        alongside the CASA software package by an international
        consortium of scientists and software developers based at the
        National Radio Astronomical Observatory (NRAO), the European
        Southern Observatory (ESO), and the National Astronomical
        Observatory of Japan (NAOJ). NRAO is a facility of the National
        Science Foundation operated under agreement by the Associated
        Universities, Inc. ALMA is a partnership of ESO (representing
        its member states), NSF (USA) and NINS (Japan), together with
        NRC (Canada) and NSC and ASIAA (Taiwan) and KASI (Republic of
        Korea), in cooperation with the Republic of Chile. The Joint
        ALMA Observatory is operated by ESO, AUI/NRAO and NAOJ.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2023AAS...24110527H},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2022PASP..134k4501C,
       author = {{CASA Team} and {Bean}, Ben and {Bhatnagar}, Sanjay and {Castro}, Sandra and {Donovan Meyer}, Jennifer and {Emonts}, Bjorn and {Garcia}, Enrique and {Garwood}, Robert and {Golap}, Kumar and {Gonzalez Villalba}, Justo and {Harris}, Pamela and {Hayashi}, Yohei and {Hoskins}, Josh and {Hsieh}, Mingyu and {Jagannathan}, Preshanth and {Kawasaki}, Wataru and {Keimpema}, Aard and {Kettenis}, Mark and {Lopez}, Jorge and {Marvil}, Joshua and {Masters}, Joseph and {McNichols}, Andrew and {Mehringer}, David and {Miel}, Renaud and {Moellenbrock}, George and {Montesino}, Federico and {Nakazato}, Takeshi and {Ott}, Juergen and {Petry}, Dirk and {Pokorny}, Martin and {Raba}, Ryan and {Rau}, Urvashi and {Schiebel}, Darrell and {Schweighart}, Neal and {Sekhar}, Srikrishna and {Shimada}, Kazuhiko and {Small}, Des and {Steeb}, Jan-Willem and {Sugimoto}, Kanako and {Suoranta}, Ville and {Tsutsumi}, Takahiro and {van Bemmel}, Ilse M. and {Verkouter}, Marjolein and {Wells}, Akeem and {Xiong}, Wei and {Szomoru}, Arpad and {Griffith}, Morgan and {Glendenning}, Brian and {Kern}, Jeff},
        title = "{CASA, the Common Astronomy Software Applications for Radio Astronomy}",
      journal = {\pasp},
     keywords = {Single-dish antennas, Aperture synthesis, Radio astronomy, Radio interferometry, Long baseline interferometry, Astronomy software, Open source software, Software documentation, Astronomy data reduction, Astronomy data analysis, 1460, 53, 1338, 1346, 932, 1855, 1866, 1869, 1861, 1858, Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Astrophysics of Galaxies, Astrophysics - High Energy Astrophysical Phenomena, Astrophysics - Solar and Stellar Astrophysics},
         year = 2022,
        month = nov,
       volume = {134},
       number = {1041},
          eid = {114501},
        pages = {114501},
     abstract = "{CASA, the Common Astronomy Software Applications, is the primary data
        processing software for the Atacama Large
        Millimeter/submillimeter Array (ALMA) and the Karl G. Jansky
        Very Large Array (VLA), and is frequently used also for other
        radio telescopes. The CASA software can handle data from single-
        dish, aperture-synthesis, and Very Long Baseline Interferometery
        (VLBI) telescopes. One of its core functionalities is to support
        the calibration and imaging pipelines for ALMA, VLA, VLA Sky
        Survey, and the Nobeyama 45 m telescope. This paper presents a
        high-level overview of the basic structure of the CASA software,
        as well as procedures for calibrating and imaging astronomical
        radio data in CASA. CASA is being developed by an international
        consortium of scientists and software engineers based at the
        National Radio Astronomy Observatory (NRAO), the European
        Southern Observatory, the National Astronomical Observatory of
        Japan, and the Joint Institute for VLBI European Research
        Infrastructure Consortium (JIV-ERIC), under the guidance of
        NRAO.}",
          doi = {10.1088/1538-3873/ac9642},
archivePrefix = {arXiv},
       eprint = {2210.02276},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022PASP..134k4501C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2022PASP..134k4502V,
       author = {{van Bemmel}, Ilse M. and {Kettenis}, Mark and {Small}, Des and {Janssen}, Michael and {Moellenbrock}, George A. and {Petry}, Dirk and {Goddi}, Ciriaco and {Linford}, Justin D. and {Rygl}, Kazi L.~J. and {Liuzzo}, Elisabetta and {Marcote}, Benito and {Bayandina}, Olga S. and {Schweighart}, Neal and {Verkouter}, Marjolein and {Keimpema}, Aard and {Szomoru}, Arpad and {van Langevelde}, Huib Jan},
        title = "{CASA on the Fringe-Development of VLBI Processing Capabilities for CASA}",
      journal = {\pasp},
     keywords = {Astronomy software, Very long baseline interferometry, Radio astronomy, Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Astrophysics of Galaxies, Astrophysics - High Energy Astrophysical Phenomena, Astrophysics - Solar and Stellar Astrophysics},
         year = 2022,
        month = nov,
       volume = {134},
       number = {1041},
          eid = {114502},
        pages = {114502},
     abstract = "{New functionality to process Very Long Baseline Interferometry (VLBI)
        data has been implemented in the CASA package. This includes two
        new tasks to handle fringe fitting and VLBI-specific amplitude
        calibration steps. Existing tasks have been adjusted to handle
        VLBI visibility data and calibration meta-data properly. With
        these updates, it is now possible to process VLBI continuum and
        spectral line observations in CASA. This article describes the
        development and implementation, and presents an outline for the
        workflow when calibrating European VLBI Network or Very Long
        Baseline Array data in CASA. Though the CASA VLBI functionality
        has already been vetted extensively as part of the Event Horizon
        Telescope data processing, in this paper we compare results for
        the same data set processed in CASA and AIPS. We find identical
        results for the two packages and conclude that CASA in some
        cases performs better, though it cannot match AIPS for single-
        core processing time. The new functionality in CASA allows for
        easy development of pipelines or Jupyter notebooks, and thus
        contributes to raising VLBI data processing to present day
        standards for accessibility, reproducibility, and reusability.}",
          doi = {10.1088/1538-3873/ac81ed},
archivePrefix = {arXiv},
       eprint = {2210.02275},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022PASP..134k4502V},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2022ASPC..532..389E,
       author = {{Emonts}, Bjorn and {Raba}, R. and {Rau}, U. and {Schiebel}, D. and {Ott}, J. and {Bean}, B. and {Bhatnagar}, S. and {Castro}, S. and {Donovan}, J. and {Garcia-Dabo}, C.~E. and {Garwood}, B. and {Golap}, K. and {Harris}, P. and {Hsieh}, M. and {Jagannathan}, P. and {Kawasaki}, W. and {Kirk}, B. and {Lopez}, J. and {McNichols}, A. and {Mehringer}, D. and {Miel}, R. and {Moellenbrock}, G. and {Pouzols}, F.~M. and {Nakazato}, T. and {Nishie}, S. and {Petry}, D. and {Pokorny}, M. and {Sekhar}, S. and {Suoranta}, V. and {Schweighart}, N. and {Steeb}, J. -W. and {Tsutsumi}, T. and {Wells}, A. and {Xiong}, W.},
        title = "{The CASA Software for Radio Astronomy: Status Update from ADASS 2020}",
    booktitle = {Astronomical Society of the Pacific Conference Series},
         year = 2022,
       editor = {{Ruiz}, Jose Enrique and {Pierfedereci}, Francesco and {Teuben}, Peter},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {532},
        month = jul,
        pages = {389},
     abstract = "{The Common Astronomy Software Applications (CASA) it the primary
        software for processing astronomical data from the Karl G.
        Jansky Very Large Array (VLA) and Atacama Large
        Millimeter/submillimeter Array (ALMA), and is frequently used
        also for other radio telescopes. These proceedings give an
        overview of several recent CASA development highlights that were
        presented at the 30th Astronomical Data Analysis Software and
        Systems (ADASS) conference. With the arrival of CASA 6, users
        now have the option to download CASA through a modular pip-wheel
        installation, giving them the flexibility to integrate CASA into
        their personalized Python environment. Another major new
        development is the introduction of a new task for joint
        deconvolution of single-dish and interferometer data. This has
        been a priority for our user base, and initial results reveal
        major improvements in combining data from single-dish and
        interferometric telescopes. We briefly also promote the external
        CARTA visualization software for use with CASA data, and
        highlight the prototype development of a next-generation CASA
        software and infrastructure for current and future radio
        telescopes, such as a Next-Generation VLA (ngVLA).}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022ASPC..532..389E},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2022ASPC..532...67R,
       author = {{Raba}, Ryan},
        title = "{CASA Next Generation Infrastructure}",
    booktitle = {Astronomical Society of the Pacific Conference Series},
         year = 2022,
       editor = {{Ruiz}, Jose Enrique and {Pierfedereci}, Francesco and {Teuben}, Peter},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {532},
        month = jul,
        pages = {67},
     abstract = "{The CASA team is working to design and prototype the next generation of
        Common Astronomy Software Applications (CASA) for radio
        interferometry data reduction. The next generation CASA
        technology stack invests heavily in Python-based frameworks for
        parallelization and data manipulation, including Dask and
        Xarray, along with a new functional design paradigm. This
        approach simplifies the code base to speed development, improve
        reliability, and reduce maintenance. Prototyping efforts are
        currently underway to include a public demonstration package
        available in the near future.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022ASPC..532...67R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2022ASPC..532..397N,
       author = {{Nakazato}, Takeshi and {Sugimoto}, Kanako and {Yoshino}, Akira and {Ezawa}, Hajime and {Hayashi}, Yohei and {Kosugi}, George and {Maekawa}, Jun and {Takahashi}, Shigeru and {Tatematsu}, Ken'ichi},
        title = "{Pipeline Calibration and Imaging for the Nobeyama 45m Radio Telescope}",
    booktitle = {Astronomical Society of the Pacific Conference Series},
         year = 2022,
       editor = {{Ruiz}, Jose Enrique and {Pierfedereci}, Francesco and {Teuben}, Peter},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {532},
        month = jul,
        pages = {397},
     abstract = "{Nobeyama 45m Radio Telescope (NRO45m) is a large single-dish radio
        telescope that has been operating for more than 35 years. The
        data processing pipeline for NRO45m (NRO Pipeline) is developed
        recently as an extension of the single-dish pipeline for the
        Atacama Large Millimeter/submillimeter Array (ALMA). The NRO
        Pipeline is able to process spectral line data taken with the
        On-The-Fly raster scan. The pipeline calibrates the data,
        protects spectral line features, subtracts residual spectral
        baseline component, detects and discards low-quality data, and
        performs imaging to produce FITS cubes for science targets. The
        pipeline is written in Python and is built on top of Common
        Astronomy Software Applications (CASA).
        \textbackslash\textbackslashThis presentation describes overall
        summary of the framework of the pipeline, details of the
        extension from the ALMA pipeline, and products of the NRO
        Pipeline. As a part of this development project, another
        application to convert the NRO45m observing data into CASA
        native data format, MeasuremntSet, is developed as well. The NRO
        Pipeline, combined with the data conversion application,
        realizes semi-automated operational workflow from the data
        acquisition through data processing to the ingestion to the data
        archive.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022ASPC..532..397N},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2021arXiv211210050P,
       author = {{Petry}, Dirk},
        title = "{Using script generators for pipeline prototyping}",
      journal = {arXiv e-prints},
     keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
         year = 2021,
        month = dec,
          eid = {arXiv:2112.10050},
        pages = {arXiv:2112.10050},
     abstract = "{Fully automated astronomical data calibration and imaging pipelines are
        difficult to develop without a good prototyping method which
        permits to bridge the time between observatory commissioning and
        the moment when the special features and possible problems of
        the data and their processing are fully understood. In this
        paper I present a method which has worked well for the ALMA
        observatory and which is sufficiently general to be transferable
        to most other projects. In short, the idea is to use a three-
        level data analysis software design (scriptable toolkit, script
        generator, automated pipeline) and a corresponding timing of the
        software development which is ramping up the effort in three
        stages starting at the beginning of construction, at the
        beginning of commissioning, and at the end of commissioning
        respectively. The important design pattern which I would like to
        underline here is the use of script generators as prototypes for
        the automated pipeline.}",
          doi = {10.48550/arXiv.2112.10050},
archivePrefix = {arXiv},
       eprint = {2112.10050},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv211210050P},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2020PASP..132b4505K,
       author = {{Kepley}, Amanda A. and {Tsutsumi}, Takahiro and {Brogan}, Crystal L. and {Indebetouw}, Remy and {Yoon}, Ilsang and {Mason}, Brian and {Donovan Meyer}, Jennifer},
        title = "{Auto-multithresh: A General Purpose Automasking Algorithm}",
      journal = {\pasp},
     keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
         year = 2020,
        month = feb,
       volume = {132},
       number = {1008},
          eid = {024505},
        pages = {024505},
     abstract = "{Producing images from interferometer data requires accurate modeling of
        the sources in the field of view, which is typically done using
        the CLEAN algorithm. Given the large number of degrees of
        freedom in interferometeric images, one constrains the possible
        model solutions for CLEAN by masking regions that contain
        emission. Traditionally this process has largely been done by
        hand. This approach is not possible with today{\textquoteright}s
        large data volumes which require automated imaging pipelines.
        This paper describes an automated masking algorithm that
        operates within CLEAN called AUTO-MULTITHRESH. This algorithm
        was developed and validated using a set of
        {\ensuremath{\sim}}1000 Atacama Large Millimeter/submillimeter
        Array (ALMA) images chosen to span a range of intrinsic
        morphology and data characteristics. It takes a top-down
        approach to producing masks: it uses the residual images to
        identify significant peaks and then expands the mask to include
        emission associated with these peaks down to lower signal-to-
        noise noise. The AUTO-MULTITHRESH algorithm has been implemented
        in CASA and has been used in production as part of the ALMA
        Imaging Pipeline starting with Cycle 5. It has been shown to be
        able to mask a wide range of emission ranging from simple point
        sources to complex extended emission with minimal tuning of the
        parameters based on the point-spread function of the data.
        Although the algorithm was developed for ALMA, it is general
        enough to have been used successfully with data from other
        interferometers with appropriate parameter tuning. Integrating
        the algorithm more deeply within the minor cycle could lead to
        future performance improvements.}",
          doi = {10.1088/1538-3873/ab5e14},
archivePrefix = {arXiv},
       eprint = {1912.04970},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020PASP..132b4505K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2020ASPC..527..571K,
       author = {{Kent}, B.~R. and {Masters}, J.~S. and {Chandler}, C.~J. and {Tobin}, J.~J. and {Marvil}, J. and {Ott}, J. and {Myers}, S.~T. and {Medlin}, D. and {Kimball}, A.~E. and {Schinzel}, F.~K. and {Lacy}, M. and {Kern}, J. and {Butler}, B.~J. and {Sugimoto}, K. and {Muders}, D. and {Williams}, S.~J. and {Geers}, V.~G.},
        title = "{Pipeline Calibration and Imaging for the Very Large Array}",
    booktitle = {Astronomical Data Analysis Software and Systems XXIX},
         year = 2020,
       editor = {{Pizzo}, R. and {Deul}, E.~R. and {Mol}, J.~D. and {de Plaa}, J. and {Verkouter}, H.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {527},
        month = jan,
        pages = {571},
     abstract = "{The VLA component of the CASA integrated pipeline produces calibrated
        measurement sets for the Karl G. Jansky Very Large Array. The
        pipeline is written in Python and consists of individual tasks
        and classes. Each task contains data processing heuristics
        designed to decide the best CASA task execution parameters for
        all VLA scheduling blocks above 1 GHz. The overall pipeline
        heuristics development has been improved through the Very Large
        Array Sky Survey (VLASS), a community and NRAO driven high-
        resolution 3 GHz continuum survey currently being carried out.
        VLASS produces imaging data products that are available to the
        astronomical community, and serves as a test platform for the
        NRAO's Science Ready Data Products (SRDP) initiative. We present
        the pipeline design and workflow as it pertains to the VLA and
        VLASS, calibration, imaging, and resulting products.
        \textbackslash\textbackslashThe pipeline is developed by an
        international consortium of scientists and software developers
        based at the National Radio Astronomical Observatory (NRAO), the
        European Southern Observatory (ESO), and the National
        Astronomical Observatory of Japan (NAOJ), and the Joint ALMA
        Observatory (JAO).}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020ASPC..527..571K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2020ASPC..527..639M,
       author = {{Masters}, J.~S. and {Kent}, B.~R. and {Sugimoto}, K. and {Indebetouw}, R. and {Brogan}, C. and {Hunter}, T. and {Kepley}, A. and {Hibbard}, J. and {Nakazato}, T. and {Kosugi}, G. and {Ezawa}, H. and {Yoshino}, A. and {Hayashi}, Y. and {Castro}, S. and {Pouzols}, F. and {Williams}, S.~J. and {Geers}, V.~C. and {Muders}, D. and {Wyrowski}, F.},
        title = "{Pipeline Calibration and Imaging for the ALMA Observatory}",
    booktitle = {Astronomical Data Analysis Software and Systems XXIX},
         year = 2020,
       editor = {{Pizzo}, R. and {Deul}, E.~R. and {Mol}, J.~D. and {de Plaa}, J. and {Verkouter}, H.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {527},
        month = jan,
        pages = {639},
     abstract = "{The Atacama Large Millimeter/sub-millimeter Array (ALMA) is an
        interferometric radio observatory in northern Chile. The ALMA
        data processing pipelines, written in Python and built largely
        upon the Common Astronomy Software Applications package (CASA),
        produce calibrated measurement sets, images and supporting
        products. The ALMA pipelines share a common code base that is
        used to calibrate data from the Karl G. Jansky Very Large Array
        as well as the Nobeyama Radio Observatory. In this paper we
        briefly describe the pipeline framework and highlight its latest
        updates to support ALMA Cycle 7 operations. The CASA Pipeline is
        developed by an international consortium of scientists and
        software developers based at the National Radio Astronomical
        Observatory (NRAO), the European Southern Observatory (ESO), and
        the National Astronomical Observatory of Japan (NAOJ) and the
        Joint ALMA Observatory (JAO).}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020ASPC..527..639M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2020ASPC..527..267E,
       author = {{Emonts}, B. and {Raba}, R. and {Moellenbrock}, G. and {Castro}, S. and {Garc{\'\i}a-Dab{\'o}}, C.~E. and {Donovan Meyer}, J. and {Ford}, P. and {Golap}, K. and {Garwood}, R. and {Gonzalez}, J. and {Kawasaki}, W. and {McNichols}, A. and {Mehringer}, D. and {Miel}, R. and {Montesino Pouzols}, F. and {Nakazato}, T. and {Nishie}, S. and {Ott}, J. and {Petry}, D. and {Rau}, U. and {Reynolds}, C. and {Schiebel}, D. and {Steeb}, J. -W. and {Suoranta}, V. and {Schweighart}, N. and {Tsutsumi}, T. and {Wells}, A. and {Bhatnagar}, S. and {Jagannathan}, P. and {Masters}, J.~S. and {Wang}, K. -S.},
        title = "{The CASA Software for Radio Astronomy: Status Update from ADASS 2019}",
     keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
    booktitle = {Astronomical Data Analysis Software and Systems XXIX},
         year = 2020,
       editor = {{Pizzo}, R. and {Deul}, E.~R. and {Mol}, J.~D. and {de Plaa}, J. and {Verkouter}, H.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {527},
        month = jan,
        pages = {267},
     abstract = "{CASA, the Common Astronomy Software Applications package, is the primary
        data processing software for the Atacama Large
        Millimeter/submillimeter Array (ALMA) and the Karl G. Jansky
        Very Large Array (VLA), and is frequently used also for other
        radio telescopes. The CASA software can process data from both
        single-dish and aperture-synthesis telescopes, and one of its
        core functionalities is to support the data reduction and
        imaging pipelines for ALMA, VLA and the VLA Sky Survey (VLASS).
        CASA has recently undergone several exciting new developments,
        including an increased flexibility in Python (CASA 6), support
        of Very Long Baseline Interferometry (VLBI), performance gains
        through parallel imaging, data visualization with the new Cube
        Analysis Rendering Tool for Astronomy (CARTA), enhanced
        reliability and testing, and modernized documentation. These
        proceedings of the 2019 Astronomical Data Analysis Software \&
        Systems (ADASS) conference give an update of the CASA project,
        and detail how these new developments will enhance user
        experience of CASA.}",
          doi = {10.48550/arXiv.1912.09437},
archivePrefix = {arXiv},
       eprint = {1912.09437},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020ASPC..527..267E},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2020ASPC..527..271R,
       author = {{Raba}, R. and {Schiebel}, D. and {Emonts}, B. and {Garwood}, R. and {Montesino Pouzols}, F. and {Castro}, S. and {Garc{\'\i}a-Dab{\'o}}, C.~E. and {Mehringer}, D. and {Suoranta}, V.},
        title = "{CASA 6: Modular Integration in Python}",
     keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
    booktitle = {Astronomical Data Analysis Software and Systems XXIX},
         year = 2020,
       editor = {{Pizzo}, R. and {Deul}, E.~R. and {Mol}, J.~D. and {de Plaa}, J. and {Verkouter}, H.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {527},
        month = jan,
        pages = {271},
     abstract = "{The Common Astronomy Software Applications (CASA), is the primary data
        processing software for the Atacama Large
        Millimeter/submillimeter Array (ALMA) and the Karl G. Jansky
        Very Large Array (VLA), and is often used also for other radio
        telescopes. CASA has always been distributed as a single,
        integrated application, including a Python interpreter and all
        the libraries, packages and modules. As part of the ongoing
        development of CASA 6, and the switch from Python 2 to 3, CASA
        will provide greater flexibility for users to integrate CASA
        into existing Python workflows by using a modular architecture
        and standard pip wheel installation. These proceedings of the
        2019 Astronomical Data Analysis Software \& Systems (ADASS)
        conference will give an overview of CASA 6 project.}",
          doi = {10.48550/arXiv.1912.09439},
archivePrefix = {arXiv},
       eprint = {1912.09439},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020ASPC..527..271R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2019ASPC..521..581C,
       author = {{Castro}, S. and {Gonzalez}, J. and {Taylor}, J. and {Bhatnagar}, S. and {Caillat}, M. and {Ford}, P. and {Golap}, K. and {Jakobs}, J. and {Kawasaki}, W. and {Kern}, J. and {Kuniyoshi}, M. and {Loveland}, S. and {Mehringer}, D. and {Miel}, R. and {Moellenbrock}, G. and {Nakazato}, T. and {Petry}, D. and {Pokorny}, M. and {Rao}, U. and {Schiebel}, D. and {Kugimoto}, K. and {Suoranta}, V. and {Tsutsumi}, T.},
        title = "{HPC Development for the ALMA Pipeline}",
    booktitle = {Astronomical Data Analysis Software and Systems XXVI},
         year = 2019,
       editor = {{Molinaro}, Marco and {Shortridge}, Keith and {Pasian}, Fabio},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {521},
        month = oct,
        pages = {581},
     abstract = "{CASA, the Common Astronomy Software Applications, has the primary goal
        of supporting the data processing needs of ALMA and VLA. The
        Parallelisation framework implemented in CASA uses MPI, the
        Message Passing Interface, which is accessible at run time
        through a wrapper of the MPI executor called mpicasa. We use MPI
        Python bindings to control the parallelisation of high-level
        CASA tasks and will soon start to use MPI C bindings for
        specific low-level C++ parts of CASA.
        \textbackslash\textbackslashThe parallelisation in CASA is
        achieved by partitioning the input MeasurementSet (MS) into
        several pieces that are virtually concatenated. Once the data is
        partitioned into a so-called Multi-MS, the CASA parallelised
        tasks are able to detect it automatically and if a cluster is
        available, sub-tasks are sent to the cluster nodes using MPI.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019ASPC..521..581C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2019ASPC..521..366G,
       author = {{Geers}, Vincent C. and {Davis}, Lindsey and {Hales}, Christopher A. and {Kent}, Brian R. and {Kern}, Jeff and {Kosugi}, George and {Muders}, Dirk and {Nakazato}, Takeshi and {Sugimoto}, Kanako and {Williams}, Stewart and {Wyrowski}, Friedrich},
        title = "{The ALMA Science Pipeline}",
    booktitle = {Astronomical Data Analysis Software and Systems XXVI},
         year = 2019,
       editor = {{Molinaro}, Marco and {Shortridge}, Keith and {Pasian}, Fabio},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {521},
        month = oct,
        pages = {366},
     abstract = "{The Atacama Large Millimeter Array (ALMA) is a radio interferometer
        composed of 66 antennas located on the Chajnantor plateau at 5
        km altitude in northern Chile. With baselines of up to 16 km,
        ALMA provides unprecedented spatial resolution and sensitivity
        in the mm/submm wavelength range for the study of star and
        galaxy formation. The ALMA project is designed to support the
        research interests of a broad and diverse astronomical
        community. As part of this support the ALMA science pipeline
        provides an automated calibration and imaging procedure which
        produces standard science quality data products for both radio
        expert and non-radio expert astronomers.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019ASPC..521..366G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2019AJ....158....3R,
       author = {{Rau}, Urvashi and {Naik}, Nikhil and {Braun}, Timothy},
        title = "{A Joint Deconvolution Algorithm to Combine Single-dish and Interferometer Data for Wideband Multiterm and Mosaic Imaging}",
      journal = {\aj},
     keywords = {methods: numerical, radio continuum: general, techniques: interferometric, techniques: image processing, Astrophysics - Instrumentation and Methods for Astrophysics},
         year = 2019,
        month = jul,
       volume = {158},
       number = {1},
          eid = {3},
        pages = {3},
     abstract = "{Imaging in radio astronomy is usually carried out with a single-dish
        radio telescope doing a raster scan of a region of the sky or
        with an interferometer that samples the visibility function of
        the sky brightness. Mosaic observations are the current standard
        for imaging large fields of view with an interferometer, and
        multifrequency observations are now routinely carried out with
        both types of telescopes to increase the continuum imaging
        sensitivity and probe spectral structure. This paper describes
        an algorithm to combine wideband data from these two types of
        telescopes in a joint iterative reconstruction scheme that can
        be applied to spectral cube or wideband multiterm imaging both
        for narrow fields of view and for mosaics. Our results
        demonstrate the ability to prevent instabilities and errors that
        typically arise when wideband or joint mosaicking algorithms are
        presented with spatial and spectral structure that is
        inadequately sampled by the interferometer alone. For comparable
        noise levels in the single-dish and interferometer data, the
        numerical behavior of this algorithm is expected to be similar
        to the idea of generating artificial visibilities from single-
        dish data. However, our discussed implementation is simpler and
        more flexible in terms of applying relative data weighting
        schemes to match noise levels while preserving flux accuracy,
        fits within standard iterative image reconstruction frameworks,
        is fully compatible with wide-field and joint mosaicking
        gridding algorithms that apply corrections specific to the
        interferometer data, and may be configured to enable spectral
        cube and wideband multiterm deconvolution for single-dish data
        alone.}",
          doi = {10.3847/1538-3881/ab1aa7},
archivePrefix = {arXiv},
       eprint = {1904.08867},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019AJ....158....3R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2018AAS...23134214K,
       author = {{Kent}, Brian R. and {Masters}, Joseph S. and {Chandler}, Claire J. and {Davis}, Lindsey E. and {Kern}, Jeffrey S. and {Ott}, Juergen and {Schinzel}, Frank K. and {Medlin}, Drew and {Muders}, Dirk and {Williams}, Stewart and {Geers}, Vincent C. and {Momjian}, Emmanuel and {Butler}, Bryan J. and {Nakazato}, Takeshi and {Sugimoto}, Kanako},
        title = "{The Very Large Array Data Processing Pipeline}",
    booktitle = {American Astronomical Society Meeting Abstracts \#231},
         year = 2018,
       series = {American Astronomical Society Meeting Abstracts},
       volume = {231},
        month = jan,
          eid = {342.14},
        pages = {342.14},
     abstract = "{We present the VLA Pipeline, software that is part of the larger
        pipeline processing framework used for the Karl G. Jansky Very
        Large Array (VLA), and Atacama Large Millimeter/sub-millimeter
        Array (ALMA) for both interferometric and single dish
        observations.Through a collection of base code jointly used by
        the VLA and ALMA, the pipeline builds a hierarchy of classes to
        execute individual atomic pipeline tasks within the Common
        Astronomy Software Applications (CASA) package. Each pipeline
        task contains heuristics designed by the team to actively decide
        the best processing path and execution parameters for
        calibration and imaging. The pipeline code is developed and
        written in Python and uses a ``context'' structure for tracking
        the heuristic decisions and processing results. The pipeline
        ``weblog'' acts as the user interface in verifying the quality
        assurance of each calibration and imaging stage. The majority of
        VLA scheduling blocks above 1 GHz are now processed with the
        standard continuum recipe of the pipeline and offer a calibrated
        measurement set as a basic data product to observatory users. In
        addition, the pipeline is used for processing data from the VLA
        Sky Survey (VLASS), a seven year community-driven endeavor
        started in September 2017 to survey the entire sky down to a
        declination of -40 degrees at S-band (2-4 GHz). This 5500 hour
        next-generation large radio survey will explore the time and
        spectral domains, relying on pipeline processing to generate
        calibrated measurement sets, polarimetry, and imaging data
        products that are available to the astronomical community with
        no proprietary period. Here we present an overview of the
        pipeline design philosophy, heuristics, and calibration and
        imaging results produced by the pipeline. Future development
        will include the testing of spectral line recipes, low signal-
        to-noise heuristics, and serving as a testing platform for
        science ready data products.The pipeline is developed as part of
        the CASA software package by an international consortium of
        scientists and software developers based at the National Radio
        Astronomical Observatory (NRAO), the European Southern
        Observatory (ESO), and the National Astronomical Observatory of
        Japan (NAOJ).}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018AAS...23134214K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2017ASPC..512..595C,
       author = {{Castro}, S. and {Gonzalez}, J. and {Taylor}, J. and {Bhatnagar}, S. and {Caillat}, M. and {Ford}, P. and {Golap}, K. and {Jakobs}, J. and {Kawasaki}, W. and {Kern}, J. and {Kuniyoshi}, M. and {Loveland}, S. and {Mehringer}, D. and {Miel}, R. and {Moellenbrock}, G. and {Nakazato}, T. and {Petry}, D. and {Pokorny}, M. and {Rao}, U. and {Rawlings}, M. and {Schiebel}, D. and {Kugimoto}, K. and {Suoranta}, V. and {Tsutsumi}, T.},
        title = "{CASA HPC and Parallelization Development for ALMA}",
    booktitle = {Astronomical Data Analysis Software and Systems XXV},
         year = 2017,
       editor = {{Lorente}, N.~P.~F. and {Shortridge}, K. and {Wayth}, R.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {512},
        month = dec,
        pages = {595},
     abstract = "{The scope of the CASA-HPC project is to parallelize CASA$^{1}$ in order
        to improve performance on computing clusters as well as modern
        PC architectures. Although our approach is applicable to a
        variety of hardware platforms, the target environments are the
        clusters operated by ALMA and the partner organizations (ESO,
        NRAO, NAOJ). This article will describe the technologies used in
        the data parallel implementation of CASA and the necessary steps
        to successfully parallelize the ALMA data processing pipeline.
        Starting in CASA 4.5.0, a parallelized execution of a full data
        analysis from data import to imaging is possible using a new
        infrastructure that is based on the Message Passing Interface
        (MPI). Briefly, MPI is a standard which addresses primarily the
        message-passing parallel programming model in a practical,
        portable, efficient and flexible way.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017ASPC..512..595C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2017eris.confE...1B,
       author = {{Biggs}, Andy and {Humphreys}, Liz},
        title = "{The ALMA (and JVLA) Pipeline}",
    booktitle = {European Radio Interferometry School},
         year = 2017,
        month = oct,
          eid = {1},
        pages = {1},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017eris.confE...1B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2017AAS...22943809D,
       author = {{Donovan Meyer}, Jennifer and {CASA Development Team} and {ALMA Pipeline Working Group} and {NAASC Software Support Team}},
        title = "{What's New in CASA: 'tclean' and the Cycle 4 ALMA Pipeline}",
    booktitle = {American Astronomical Society Meeting Abstracts \#229},
         year = 2017,
       series = {American Astronomical Society Meeting Abstracts},
       volume = {229},
        month = jan,
          eid = {438.09},
        pages = {438.09},
     abstract = "{CASA, the Common Astronomy Software Applications package, undergoes
        continuous development to support calibration and imaging of
        astronomical data at radio wavelengths for both single dish and
        interferometric telescopes. It is largely focused on supporting
        the post-processing needs of the next generation of radio
        telescopes such as ALMA and the JVLA. The most recent release of
        CASA, version 4.7, includes major upgrades in its imaging
        capabilities via the implementation of a task called 'tclean',
        which will eventually replace the current imaging task 'clean'.
        It has a new, more straightforward interface, allows more
        combinations of imaging algorithms, has a more flexible outlier
        approach, and includes algorithms for autoboxing. Further, the
        new 'tclean' task has been implemented in the Cycle 4 ALMA
        Interferometric Pipeline with great success; this pipeline
        software can be obtained bundled with CASA 4.7 at
        https://casa.nrao.edu/. A major goal of the ALMA project [and
        the National Radio Astronomical Observatory (NRAO)] is to
        provide Science-Ready Data Products to our user community, and
        the ALMA Cycle 4 Pipeline is a major step forward in that
        direction.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017AAS...22943809D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2016AJ....152..124R,
       author = {{Rau}, U. and {Bhatnagar}, S. and {Owen}, F.~N.},
        title = "{Deep Wideband Single Pointings and Mosaics in Radio Interferometry: How Accurately Do We Reconstruct Intensities and Spectral Indices of Faint Sources?}",
      journal = {\aj},
     keywords = {methods: data analysis, techniques: image processing, techniques: interferometric, Astrophysics - Instrumentation and Methods for Astrophysics},
         year = 2016,
        month = nov,
       volume = {152},
       number = {5},
          eid = {124},
        pages = {124},
     abstract = "{Many deep wideband wide-field radio interferometric surveys are being
        designed to accurately measure intensities, spectral indices,
        and polarization properties of faint source populations. In this
        paper, we compare various wideband imaging methods to evaluate
        the accuracy to which intensities and spectral indices of
        sources close to the confusion limit can be reconstructed. We
        simulated a wideband single-pointing (C-array, L-Band (1-2 GHz))
        and 46-pointing mosaic (D-array, C-Band (4-8 GHz)) JVLA
        observation using a realistic brightness distribution ranging
        from 1 {\ensuremath{\mu}}Jy to 100 mJy and time-, frequency-,
        polarization-, and direction-dependent instrumental effects. The
        main results from these comparisons are (a) errors in the
        reconstructed intensities and spectral indices are larger for
        weaker sources even in the absence of simulated noise, (b)
        errors are systematically lower for joint reconstruction methods
        (such as Multi-Term Multi-Frequency-Synthesis (MT-MFS)) along
        with A-Projection for accurate primary beam correction, and (c)
        use of MT-MFS for image reconstruction eliminates Clean-bias
        (which is present otherwise). Auxiliary tests include solutions
        for deficiencies of data partitioning methods (e.g., the use of
        masks to remove clean bias and hybrid methods to remove
        sidelobes from sources left un-deconvolved), the effect of
        sources not at pixel centers, and the consequences of various
        other numerical approximations within software implementations.
        This paper also demonstrates the level of detail at which such
        simulations must be done in order to reflect reality, enable one
        to systematically identify specific reasons for every trend that
        is observed, and to estimate scientifically defensible imaging
        performance metrics and the associated computational complexity
        of the algorithms/analysis procedures.
        \textbackslash\textbackslashThe National Radio Astronomy
        Observatory is a facility of the National Science Foundation
        operated under cooperative agreement by Associated Universities,
        Inc.}",
          doi = {10.3847/0004-6256/152/5/124},
archivePrefix = {arXiv},
       eprint = {1605.07640},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016AJ....152..124R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2016alma.confE...1H,
       author = {{Humphreys}, Elizabeth and {Miura}, Rie and {Brogan}, Crystal L. and {Hibbard}, John and {Hunter}, Todd R. and {Indebetouw}, Remy},
        title = "{The ALMA Science Pipeline: Current Status}",
    booktitle = {Proceedings of the 2016 ALMA Conference},
         year = 2016,
        month = sep,
          eid = {1},
        pages = {1},
     abstract = "{The ALMA Science Pipeline is being developed for the automated
        calibration and imaging of ALMA interferometric and single-dish
        data. The calibration Pipeline for interferometric data was
        accepted for use by ALMA Science Operations in 2014, and for
        single-dish data end-to-end processing in 2015. However, work is
        ongoing to expand the use cases for which the Pipeline can be
        used e.g. for higher frequency and lower signal-to-noise
        datasets, and for new observing modes. A current focus includes
        the commissioning of science target imaging for interferometric
        data. For the Single Dish Pipeline, the line finding algorithm
        used in baseline subtraction and baseline flagging heuristics
        have been greately improved since the prototype used for data
        from the previous cycle. These algorithms, unique to the
        Pipeline, produce better results than standard manual processing
        in many cases. In this poster, we report on the current status
        of the Pipeline capabilities, present initial results from the
        Imaging Pipeline, and the smart line finding and flagging
        algorithm used in the Single Dish Pipeline. The Pipeline is
        released as part of CASA (the Common Astronomy Software
        Applications package).}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016alma.confE...1H},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2015ASPC..499..355S,
       author = {{Shinnaga}, H. and {Humphreys}, E. and {Indebetouw}, R. and {Villard}, E. and {Kern}, J. and {Davis}, L. and {Miura}, R.~E. and {Nakazato}, T. and {Sugimoto}, K. and {Kosugi}, G. and {Akiyama}, E. and {Muders}, D. and {Wyrowski}, F. and {Williams}, S. and {Lightfoot}, J. and {Kent}, B. and {Momjian}, E. and {Hunter}, T. and {ALMA Pipeline Team}},
        title = "{ALMA Pipeline: Current Status}",
    booktitle = {Revolution in Astronomy with ALMA: The Third Year},
         year = 2015,
       editor = {{Iono}, D. and {Tatematsu}, K. and {Wootten}, A. and {Testi}, L.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {499},
        month = dec,
        pages = {355},
     abstract = "{The ALMA Pipeline is the automated data reduction tool that runs on ALMA
        data. Current version of the ALMA pipeline produces science
        quality data products for standard interferometric observing
        modes up to calibration process. The ALMA Pipeline is comprised
        of (1) heuristics in the form of Python scripts that select the
        best processing parameters, and (2) contexts that are given for
        book-keeping purpose of data processes. The ALMA Pipeline
        produces a ``weblog'' that showcases detailed plots for users to
        judge how each step of calibration processes are treated. The
        ALMA Interferometric Pipeline was conditionally accepted in
        March 2014 by processing Cycle 0 and Cycle 1 data sets. From
        Cycle 2, ALMA Pipeline is used for ALMA data reduction and
        quality assurance for the projects whose observing modes are
        supported by the ALMA Pipeline. Pipeline tasks are available
        based on CASA version 4.2.2, and the first public pipeline
        release called CASA 4.2.2-pipe has been available since October
        2014. One can reduce ALMA data both by CASA tasks as well as by
        pipeline tasks by using CASA version 4.2.2-pipe.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015ASPC..499..355S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2015ASPC..495..301D,
       author = {{Davis}, L. and {Williams}, S. and {Nakazato}, T. and {Lightfoot}, J. and {Muders}, D. and {Kent}, B.},
        title = "{The ALMA Pipeline Procedure Execution Framework}",
    booktitle = {Astronomical Data Analysis Software an Systems XXIV (ADASS XXIV)},
         year = 2015,
       editor = {{Taylor}, A.~R. and {Rosolowsky}, E.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {495},
        month = sep,
        pages = {301},
     abstract = "{The ALMA pipeline processes data taken in standard observing modes. The
        ALMA pipeline execution framework is responsible for executing
        the standard reduction procedure for each standard mode. The
        execution framework is written in Python. The pipeline reduction
        procedures are layered on and run inside the CASA package. The
        framework is flexible enough to support observatory operations,
        reprocessing, commissioning and testing, and user desktop
        reprocessing.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015ASPC..495..301D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2014SPIE.9149E..0ZS,
       author = {{Schnee}, Scott L. and {Brogan}, Crystal and {Espada}, Daniel and {Humphreys}, Elizabeth and {Komugi}, Shinya and {Petry}, Dirk and {Vila-Vilaro}, Baltasar and {Villard}, Eric},
        title = "{The human pipeline: distributed data reduction for ALMA}",
     keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
    booktitle = {Observatory Operations: Strategies, Processes, and Systems V},
         year = 2014,
       editor = {{Peck}, Alison B. and {Benn}, Chris R. and {Seaman}, Robert L.},
       series = {Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series},
       volume = {9149},
        month = aug,
          eid = {91490Z},
        pages = {91490Z},
     abstract = "{Users of the Atacama Large Millimeter/submillimeter Array (ALMA) are
        provided with calibration and imaging products in addition to
        raw data. In Cycle 0 and Cycle 1, these products are produced by
        a team of data reduction experts spread across Chile, East Asia,
        Europe, and North America. This article discusses the lines of
        communication between the data reducers and ALMA users that
        enable this model of distributed data reduction. This article
        also discusses the calibration and imaging scripts that have
        been provided to ALMA users in Cycles 0 and 1, and what will be
        different in future Cycles.}",
          doi = {10.1117/12.2057940},
archivePrefix = {arXiv},
       eprint = {1407.1770},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2014SPIE.9149E..0ZS},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2014ASPC..485..383M,
       author = {{Muders}, D. and {Wyrowski}, F. and {Lightfoot}, J. and {Williams}, S. and {Nakazato}, T. and {Kosugi}, G. and {Davis}, L. and {Kern}, J.},
        title = "{The ALMA Pipeline}",
    booktitle = {Astronomical Data Analysis Software and Systems XXIII},
         year = 2014,
       editor = {{Manset}, N. and {Forshay}, P.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {485},
        month = may,
        pages = {383},
     abstract = "{The Atacama Large Millimeter Array (ALMA) is a radio interferometer that
        is being built on the Chajnantor plateau at 5000 m altitude in
        the Atacama desert in Chile. It will consist of 66 telescopes
        organized in three arrays providing baselines up to 16 km with a
        zoom configuration including zero spacings. ALMA will provide
        unprecedented spatial resolution and sensitivity in the mm/submm
        wavelength range to study star and galaxy formation. The ALMA
        project intends to reach a broad astronomical community. An
        automatic reduction pipeline is required to deliver science
        quality data products also for non-experts. The ALMA Pipeline is
        being developed as a set of additional tasks based on the CASA
        (Common Astronomy Software Applications) data reduction package.
        End-to-end processing for interferometry and single dish data
        has been implemented. The pipeline features are being
        commissioned incrementally using ALMA Cycle 0 and Cycle 1 data.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2014ASPC..485..383M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2012ASPC..461..185D,
       author = {{Davis}, L. and {Muders}, D. and {Humphreys}, E. and {Stoehr}, F. and {Leon Tanne}, S. and {Saito}, M.},
        title = "{Translating ALMA Science Goals into Pipeline Processing Requests}",
    booktitle = {Astronomical Data Analysis Software and Systems XXI},
         year = 2012,
       editor = {{Ballester}, P. and {Egret}, D. and {Lorente}, N.~P.~F.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {461},
        month = sep,
        pages = {185},
     abstract = "{Capturing ALMA user science goals at proposal submission time and
        factoring these goals into a set of standard pipeline processing
        units, a set of standard observing units, and a set of user
        intents which can be encapsulated in a pipeline processing
        request, is key to the successful operation of the ALMA science
        pipeline.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2012ASPC..461..185D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2012ASPC..461..849P,
       author = {{Petry}, Dirk and {CASA Development Team}},
        title = "{Analysing ALMA Data with CASA}",
     keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Physics - Data Analysis, Statistics and Probability},
    booktitle = {Astronomical Data Analysis Software and Systems XXI},
         year = 2012,
       editor = {{Ballester}, P. and {Egret}, D. and {Lorente}, N.~P.~F.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {461},
        month = sep,
        pages = {849},
     abstract = "{The radio astronomical data analysis package CASA was selected to be the
        designated tool for observers to analyse the data from the
        Atacama Large mm/sub-mm Array (ALMA) which is under construction
        and has recently started taking its first science data (Cycle
        0). CASA is a large package which is being developed by NRAO
        with major contributions from ESO and NAOJ. Generally, all radio
        data from interferometers and single dish observatories can be
        analysed with CASA, but the development focuses presently on the
        needs of the new observatories EVLA and ALMA. This article
        describes the main features of CASA and the typical analysis
        steps for ALMA data.}",
          doi = {10.48550/arXiv.1201.3454},
archivePrefix = {arXiv},
       eprint = {1201.3454},
 primaryClass = {astro-ph.IM},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2012ASPC..461..849P},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2009ASPC..411..306D,
       author = {{Davis}, L.~E.},
        title = "{An Overview of the ALMA Pipeline System}",
    booktitle = {Astronomical Data Analysis Software and Systems XVIII},
         year = 2009,
       editor = {{Bohlender}, D.~A. and {Durand}, D. and {Dowler}, P.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {411},
        month = sep,
        pages = {306},
     abstract = "{An overview of the ALMA Pipeline system is presented. The requirements,
        architecture, current development status, and testing strategies
        for each major component of the system are described.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2009ASPC..411..306D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2008ASPC..394..573L,
       author = {{Lightfoot}, J. and {Kosugi}, G. and {Wyrowski}, F. and {Zapata}, L. and {Muders}, D. and {Boone}, F. and {Tsutsumi}, T. and {Davis}, L. and {Wilson}, C. and {Shepherd}, D.},
        title = "{ALMA Pipeline Heuristics}",
    booktitle = {Astronomical Data Analysis Software and Systems XVII},
         year = 2008,
       editor = {{Argyle}, R.~W. and {Bunclark}, P.~S. and {Lewis}, J.~R.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {394},
        month = aug,
        pages = {573},
     abstract = "{The ALMA Pipeline Heuristics system is being developed to reduce
        automatically data taken with the standard observing modes. The
        goals are to make ALMA comfortable to use for astronomers who
        are new to radio interferometry and to provide reduced results
        of publishable quality. The reduction sequence will continue to
        develop as experience is gained at the telescope, so it is
        important that the system has a framework and interface that are
        flexible and easy to use. Observing modes to be handled include
        single field interferometry, mosaics, single dish `on the fly'
        maps, and combinations of these. The data will be produced by
        the main ALMA array, the Alma Compact Array, and single dish
        antennas. The reduction sequence is logged to a collection of
        html files that can examined using a standard browser for
        verification of the process. The reduction is performed by a
        Python script and classes bound to the CASA libraries.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2008ASPC..394..573L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2007ASPC..376..241M,
       author = {{Muders}, D. and {Boone}, F. and {Wyrowski}, F. and {Lightfoot}, J. and {Kosugi}, G. and {Wilson}, C. and {Davis}, L. and {Shepherd}, D.},
        title = "{ALMA Pipeline Heuristics}",
    booktitle = {Astronomical Data Analysis Software and Systems XVI},
         year = 2007,
       editor = {{Shaw}, R.~A. and {Hill}, F. and {Bell}, D.~J.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {376},
        month = oct,
        pages = {241},
     abstract = "{The Atacama Large Millimeter Array / Atacama Compact Array (ALMA / ACA)
        Pipeline Heuristics system is being developed to automatically
        reduce data taken with the standard observing modes such as
        single fields, mosaics or on-the-fly maps. The goal is to make
        ALMA user-friendly to astronomers who are not experts in radio
        interferometry. The Pipeline Heuristics must capture the expert
        knowledge required to provide data products that can be used
        without further processing. The Pipeline Heuristics system is
        being developed as a set of Python scripts using as the data
        processing engines the Common Astronomy Software Applications
        (CASA[PY]) libraries and the ATNF Spectral Analysis Package
        (ASAP). The interferometry heuristics scripts currently provide
        an end-to-end process for the single field mode comprising
        flagging, initial calibration, re-flagging, re-calibration, and
        imaging of the target data. A Java browser provides user-
        friendly access to the heuristics results. The initial single-
        dish heuristics scripts implement automatic spectral line
        detection, baseline fitting and image gridding. The resulting
        data cubes are analyzed to detect source emission spectrally and
        spatially in order to calculate signal-to-noise ratios for
        comparison against the science goals specified by the observer.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2007ASPC..376..241M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2007ASPC..376..127M,
       author = {{McMullin}, J.~P. and {Waters}, B. and {Schiebel}, D. and {Young}, W. and {Golap}, K.},
        title = "{CASA Architecture and Applications}",
    booktitle = {Astronomical Data Analysis Software and Systems XVI},
         year = 2007,
       editor = {{Shaw}, R.~A. and {Hill}, F. and {Bell}, D.~J.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {376},
        month = oct,
        pages = {127},
     abstract = "{We describe the CASA (Common Astronomy Software Applications) package,
        its design and capabilities. CASA is a suite of applications for
        the reduction and analysis of radio astronomical data with a
        Python interface.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2007ASPC..376..127M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2006ASPC..351..327D,
       author = {{Davis}, L.~E.},
        title = "{The ALMA Pipeline Infrastructure}",
    booktitle = {Astronomical Data Analysis Software and Systems XV},
         year = 2006,
       editor = {{Gabriel}, C. and {Arviset}, C. and {Ponz}, D. and {Enrique}, S.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {351},
        month = jul,
        pages = {327},
     abstract = "{The ALMA pipeline infrastructure provides the software interfaces,
        packages, and services required to support the ALMA quicklook
        and science pipeline operations and to integrate them into the
        ALMA Software System.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2006ASPC..351..327D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2006ASPC..351..315L,
       author = {{Lightfoot}, J. and {Wyrowski}, F. and {Muders}, D. and {Boone}, F. and {Davis}, L. and {Shepherd}, D. and {Wilson}, C.},
        title = "{ALMA Pipeline Heuristics}",
    booktitle = {Astronomical Data Analysis Software and Systems XV},
         year = 2006,
       editor = {{Gabriel}, C. and {Arviset}, C. and {Ponz}, D. and {Enrique}, S.},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {351},
        month = jul,
        pages = {315},
     abstract = "{The ALMA (Atacama Large Millimeter Array) Pipeline Heuristics system is
        being developed to automatically reduce data taken with the
        standard observing modes. The goal is to make ALMA user-friendly
        to astronomers who are not experts in radio interferometry. The
        Pipeline Heuristics system must capture the expert knowledge
        required to provide data products that can be used without
        further processing. \textbackslash\textbackslashObserving modes
        to be processed by the system include single field
        interferometry, mosaics and single dish `on-the-fly' maps, and
        combinations of these modes. The data will be produced by the
        main ALMA array, the ALMA Compact Array (ACA) and single dish
        antennas. \textbackslash\textbackslashThe Pipeline Heuristics
        system is being developed as a set of Python scripts. For
        interferometry these use as data processing engines the
        CASA/AIPS++ libraries and their bindings as CORBA objects within
        the ALMA Common Software (ACS).
        \textbackslash\textbackslashInitial development has used VLA and
        Plateau de Bure data sets to build and test a heuristic script
        capable of reducing single field data. In this paper we describe
        the reduction datapath and the algorithms used at each stage.
        Test results are presented. The path for future development is
        outlined.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2006ASPC..351..315L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{2004ASPC..314...89D,
       author = {{Davis}, L.~E. and {Glendenning}, B.~E. and {Tody}, D.},
        title = "{The ALMA Prototype Science Pipeline}",
    booktitle = {Astronomical Data Analysis Software and Systems (ADASS) XIII},
         year = 2004,
       editor = {{Ochsenbein}, Francois and {Allen}, Mark G. and {Egret}, Daniel},
       series = {Astronomical Society of the Pacific Conference Series},
       volume = {314},
        month = jul,
        pages = {89},
     abstract = "{In this paper we describe the ALMA Prototype Pipeline Project, a joint
        ALMA Computing IPT / NRAO Interferometry Software Division
        initiative to develop a Python based pipeline processing
        capability for ALMA.}",
       adsurl = {https://ui.adsabs.harvard.edu/abs/2004ASPC..314...89D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

