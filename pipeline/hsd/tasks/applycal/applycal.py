import os
from typing import TYPE_CHECKING, List, Optional, Union

import numpy

import pipeline.infrastructure as infrastructure
import pipeline.infrastructure.vdp as vdp
import pipeline.infrastructure.sessionutils as sessionutils
from pipeline.domain.datatable import DataTableImpl as DataTable
from pipeline.domain import DataType
from pipeline.h.tasks.applycal.applycal import SerialApplycal, ApplycalInputs, ApplycalResults
from pipeline.infrastructure import casa_tools
from pipeline.infrastructure import task_registry

if TYPE_CHECKING:
    from pipeline.domain import MeasurementSet
    from pipeline.infrastructure import Context
    from pipeline.infrastructure import CalApplication

LOG = infrastructure.get_logger(__name__)


class SDApplycalInputs(ApplycalInputs):
    """
    ApplycalInputs defines the inputs for the Applycal pipeline task.
    """
    # use common implementation for parallel inputs argument
    parallel = sessionutils.parallel_inputs_impl()

    flagdetailedsum = vdp.VisDependentProperty(default=True)
    intent = vdp.VisDependentProperty(default='TARGET')

    def __init__(self,
                 context: 'Context',
                 output_dir: Optional[str] = None,
                 vis: Optional[Union[str, List[str]]] = None,
                 field: Optional[Union[str, List[str]]] = None,
                 spw: Optional[Union[str, List[str]]] = None,
                 antenna: Optional[Union[str, List[str]]] = None,
                 intent: Optional[Union[str, List[str]]] = None,
                 parang: Optional[bool] = None,
                 applymode: Optional[str] = None,
                 flagbackup: Optional[bool] = None,
                 flagsum: Optional[bool] = None,
                 flagdetailedsum: Optional[bool] = None,
                 parallel: Optional[Union[bool, str]] = None):
        """Inputs for SDApplycal task.

        Args:
            context: Pipeline context.
            output_dir: Output directory.
            vis: Name of MS or list of MS names.
            field: Field selection.
            spw: Spectral window (spw) selection.
            antenna: Antenna selection.
            intent: Observing intent selection.
            parang: Apply parallactic angle correction. Not used.
            applymode: Calibration mode. Defaults to 'calflagstrict'.
            flagbackup: Automatically back up flag state before run. Defaults to True.
            flagsum: Run flagdata task for flagging summary. Defaults to True.
            flagdetailedsum: Generate detailed flagging summary. Defaults to False.
            parallel: Execute using CASA HPC functionality, if available.
                      Default is None, which intends to turn on parallel
                      processing if possible.
        """
        super().__init__(
            context, output_dir=output_dir, vis=vis,
            field=field, spw=spw, antenna=antenna, intent=intent,
            parang=parang, applymode=applymode, flagbackup=flagbackup,
            flagsum=flagsum, flagdetailedsum=flagdetailedsum,
            parallel=parallel
        )


class SDApplycalResults(ApplycalResults):
    """
    ApplycalResults generated by SDApplycal task.
    Please see parent task's docstring for detail.
    """
    def __init__(self,
                 applied: Optional[List['CalApplication']] = None,
                 data_type: Optional[DataType] = None):
        """Construct SDApplycalResults instance.
        Please see parent task's docstring for detail.

        Args:
            applied: caltables applied by this task.
            data_type: data type enum.
        """
        super().__init__(applied, data_type=data_type)


class SerialSDApplycal(SerialApplycal):
    """
    Applycal executes CASA applycal tasks for the current context state,
    applying calibrations registered with the pipeline context to the target
    measurement set.

    Applying the results from this task to the context marks the referred
    tables as applied. As a result, they will not be included in future
    on-the-fly calibration arguments.
    """
    Inputs = SDApplycalInputs

    def modify_task_args(self, task_args: dict) -> dict:
        """Override template arguments for applycal execution.

        This method receives template task_args created by the parent task,
        and override it with our SD-specific antenna selection arguments.

        Args:
            task_args: Template arguments for applycal execution.

        Returns:
            Updated task arguments.
        """
        task_args['antenna'] = '*&&&'
        return task_args

    def _get_flagsum_arg(self, args: dict) -> dict:
        """Update arguments for flag summary.

        According to the requirement in CAS-8813, flag fraction should be
        based on target instead of total.

        Args:
            args: Template arguments for flag summary.

        Returns:
            Updated task arguments.
        """
        task_args = super()._get_flagsum_arg(args)
        task_args['intent'] = 'OBSERVE_TARGET#ON_SOURCE'
        return task_args

    def _tweak_flagkwargs(self, template: List[str]) -> List[str]:
        """Override flagging commands.

        According to the requirement in CAS-8813, flag fraction should be
        based on target instead of total.

        Args:
            template: List of flagging commands.

        Returns:
            Updated flagging commands.
        """
        # use of ' rather than " is required to prevent escaping of flagcmds
        return [row + " intent='OBSERVE_TARGET#ON_SOURCE'" for row in template]

    def prepare(self):
        # execute Applycal
        results = super().prepare()

        # Update Tsys in datatable
        context = self.inputs.context
        # this task uses _handle_multiple_vis framework
        msobj = self.inputs.ms
        origin_basename = os.path.basename(msobj.origin_ms)
        datatable_name = os.path.join(context.observing_run.ms_datatable_name, origin_basename)
        datatable = DataTable()
        datatable.importdata(name=datatable_name, readonly=False)
        datatable._update_flag(msobj.name)
        for calapp in results.applied:
            filename = os.path.join(context.output_dir, calapp.vis)
            fieldids = [fieldobj.id for fieldobj in msobj.get_fields(calapp.field)]
            for _calfrom in calapp.calfrom:
                if _calfrom.caltype == 'tsys':
                    LOG.info('Updating Tsys for {0}'.format(os.path.join(calapp.vis)))
                    tsystable = _calfrom.gaintable
                    spwmap = _calfrom.spwmap
                    gainfield = _calfrom.gainfield
                    datatable._update_tsys(context, filename, tsystable, spwmap, fieldids, gainfield)

        # here, full export is necessary
        datatable.exportdata(minimal=False)

        sdresults = SDApplycalResults(applied=results.applied, data_type=self.applied_data_type)
        sdresults.summaries = results.summaries
        if hasattr(results, 'flagsummary'):
            sdresults.flagsummary = results.flagsummary

        # set unit according to applied calibration
        set_unit(msobj, results.applied)

        return sdresults


def set_unit(ms: 'MeasurementSet', calapp: List['CalApplication']):
    """Set unit to MS data column according to applied calibrations.

    Args:
        ms: MeasurementSet domain object.
        calapp: List of CalApplication objects.
    """
    target_fields = ms.get_fields(intent='TARGET')
    data_units = dict((f.id, '') for f in target_fields)
    for a in calapp:
        calto = a.calto
        field_name = calto.field
        if len(field_name) == 0:
            field = ms.get_fields(intent='TARGET')
        else:
            field = [f for f in ms.get_fields(name=field_name) if 'TARGET' in f.intents]
        if len(field) == 0:
            continue

        assert len(field) == 1
        field_id = field[0].id
        caltypes = [cf.caltype for cf in a.calfrom]
        if ('ps' in caltypes) and ('tsys' in caltypes):
            data_units[field_id] = 'K'
        else:
            LOG.warning('Calibration of {} (field {}) is not correct. Missing pscal and/or tsyscal.'.format(ms.basename, field_name))
        if 'amp' in caltypes or 'gaincal' in caltypes:
            if data_units[field_id] == 'K':
                data_units[field_id] = 'Jy'

    unit_list = numpy.asarray(list(data_units.values()))
    if numpy.all(unit_list == 'K'):
        data_unit = 'K'
    elif numpy.all(unit_list == 'Jy'):
        data_unit = 'Jy'
    elif numpy.any(unit_list == 'Jy'):
        LOG.warning(
            'Calibration of {} is not correct. Some of calibrations (pscal, tsyscal, ampcal) are missing.'.fomrat(ms.basename))
        data_unit = ''
    else:
        data_unit = ''

    if data_unit != '':
        with casa_tools.TableReader(ms.name, nomodify=False) as tb:
            colnames = tb.colnames()
            target_columns = set(colnames) & set(['DATA', 'FLOAT_DATA', 'CORRECTED_DATA'])
            for col in target_columns:
                tb.putcolkeyword(col, 'UNIT', data_unit)


# Tier-0 parallelization
@task_registry.set_equivalent_casa_task('hsd_applycal')
@task_registry.set_casa_commands_comment('Calibrations are applied to the data. Final flagging summaries are computed')
class SDApplycal(sessionutils.ParallelTemplate):
    Inputs = SDApplycalInputs
    Task = SerialSDApplycal
