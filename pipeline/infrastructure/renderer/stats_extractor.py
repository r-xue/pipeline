"""
Adaped from regression extractor classes
"""
import abc
import collections
import re
from collections import OrderedDict
from typing import List, Union
from pipeline.infrastructure.renderer import regression
from pipeline.infrastructure import pipeline_statistics

from pipeline.h.tasks.applycal.applycal import ApplycalResults
from pipeline.hif.tasks.applycal.ifapplycal import IFApplycal
from pipeline.hifa.tasks.fluxscale.gcorfluxscale import GcorFluxscaleResults
from pipeline.hifa.tasks.gfluxscaleflag.resultobjects import GfluxscaleflagResults

from pipeline.hifa.tasks.flagging.flagdeteralma import FlagDeterALMAResults
from pipeline.infrastructure.basetask import Results, ResultsList
from pipeline.infrastructure.launcher import Context
from pipeline.infrastructure import logging
from pipeline.h.tasks.common import flagging_renderer_utils as flagutils
import pipeline.infrastructure.utils as utils

LOG = logging.get_logger(__name__)


class StatsExtractor(regression.RegressionExtractor):
    """The mandatory base class

    # the Results class this handler is expected to handle
    result_cls = None
    # if result_cls is a list, the type of classes it is expected to contain
    child_cls = None
    # the task class that generated the results, or None if it should handle
    # all results of this type regardless of which task generated it
    generating_task = None"""

    @abc.abstractmethod
    def handle(self, result:Results, context=None):
        """
        [Abstract] Extract values for testing.

        This method should return a dict of

        {'applycal.new_flags.science': 0.34,
         'applycal.new_flags.bandpass': 0.53}

        :param result:
        :return:
        """
        raise NotImplemented


class StatsExtractorRegistry(object):
    """
    The registry and manager of the regression result extractor framework.

    The responsibility of the RegressionResultRegistry is to pass Results to
    RegressionExtractors that can handle them.
    """

    def __init__(self):
        """Constractor of this class."""
        self.__plugins_loaded = False
        self.__handlers = []

    def add_handler(self, handler: StatsExtractor) -> None:
        """
        Push RegressionExtractor into handlers list __handler.

        Args:
            handler: RegressionExtractor
        """
        task = handler.generating_task.__name__ if handler.generating_task else 'all'
        child_name = ''
        if hasattr(handler.child_cls, '__name__'):
            child_name = handler.child_cls.__name__
        elif isinstance(handler.child_cls, collections.abc.Iterable):
            child_name = str([x.__name__ for x in handler.child_cls])
        container = 's of %s' % child_name
        s = '{}{} results generated by {} tasks'.format(handler.result_cls.__name__, container, task)
        LOG.debug('Registering {} as new regression result handler for {}'.format(handler.__class__.__name__, s))
        self.__handlers.append(handler)

    def handle(self, result: Union[Results, ResultsList], context=None):
        """
        Extract values from corresponding Extractor object of Result object.
        """
        if not self.__plugins_loaded:
            for plugin_class in get_all_subclasses(StatsExtractor):
                self.add_handler(plugin_class())
            self.__plugins_loaded = True

        # this is the list which will contain extracted values tuples
        extracted = []

        # Process leaf results first
        if isinstance(result, collections.abc.Iterable):
            for r in result:
                d = self.handle(r, context)
                union(extracted, d)

        # process the group-level results.
        for handler in self.__handlers:
            if handler.is_handler_for(result):
                LOG.debug('{} extracting stats results for {}'.format(handler.__class__.__name__,
                                                                           result.__class__.__name__))
                d = handler.handle(result, context)
                union(extracted, d)

        return extracted


# default StatsExtractorRegistry initialization
registry = StatsExtractorRegistry()


class FlagDeterALMAResultsExtractor(StatsExtractor):
    result_cls = FlagDeterALMAResults
    child_cls = None

    def handle(self, result: FlagDeterALMAResults, context) -> OrderedDict:

        intents_to_summarise = flagutils.intents_to_summarise(context)
        flag_table_intents = ['TOTAL', 'SCIENCE SPWS']
        flag_table_intents.extend(intents_to_summarise)

        flag_totals = {}
        flag_totals = utils.dict_merge(flag_totals,
            flagutils.flags_for_result(result, context, intents_to_summarise=intents_to_summarise))

        reasons_to_export = ['online', 'shadow', 'qa0', 'qa2', 'before', 'template']

        output_dict = {}
        for ms in flag_totals:
            output_dict[ms] = {}
            for reason in flag_totals[ms]:
                for intent in flag_totals[ms][reason]:
                    if reason in reasons_to_export:
                        if "TOTAL" in intent:
                            new = float(flag_totals[ms][reason][intent][0])
                            total = float(flag_totals[ms][reason][intent][1])
                            percentage = new/total * 100
                            output_dict[ms][reason] = percentage
        mous = context.get_oussid()
        ps = pipeline_statistics.PipelineStatistics(name="flagdata_percentage",
                                                    value=output_dict,
                                                    longdesc="temporory value for testing",
                                                    eb=ms,
                                                    mous=mous,
                                                    level="EB")
        return ps


class FluxcalflagStatsExtractor(StatsExtractor):
    result_cls = GfluxscaleflagResults
    child_cls = None

    def handle(self, result:GfluxscaleflagResults, context):
        """
        Args:
            result: GfluxscaleflagResults object
        """
        summaries_by_name = {s['name']: s for s in result.cafresult.summaries}

        num_flags_before = summaries_by_name['before']['flagged']

        if 'after' in summaries_by_name:
            num_flags_after = summaries_by_name['after']['flagged']
        else:
            num_flags_after = num_flags_before

        ps = pipeline_statistics.PipelineStatistics(name="fluxscaleflags",
                                                    value=int(num_flags_after),
                                                    longdesc="rows after",
                                                    mous=context.get_oussid(),
                                                    level="MOUS")
        return ps


class ApplycalRegressionExtractor(StatsExtractor):
    """
    Stats test result extractor for applycal tasks.
    """

    result_cls = ApplycalResults
    child_cls = None
    generating_task = IFApplycal

    def handle(self, result: ApplycalResults, context):
        """
        Args:
            result: ApplycalResults object

        Returns:
            OrderedDict[str, float]
        """
        summaries_by_name = {s['name']: s for s in result.summaries}
        num_flags_after = summaries_by_name['applycal']['flagged']
        ps = pipeline_statistics.PipelineStatistics(name="applycal_flags",
                                                    value=int(num_flags_after),
                                                    longdesc="rows after",
                                                    mous=context.get_oussid(),
                                                    level="MOUS")
        return ps


def get_stats_from_results(context: Context) -> List[str]:
    """
    get stats required to be fetched from the results.
    """
    unified = []
    for results_proxy in context.results:
        results = results_proxy.read()
        union(unified, registry.handle(results, context))

    return unified


def union(l1: List, new) -> List:
    """
    Combines l1 which is always a list, with
    new, which could be a list or a PipelineStatistics object
    """
    union = l1

    if isinstance(new, list):
        for elt in new:
            union.append(elt)
    else:
        union.append(elt)

    return union


def get_all_subclasses(cls: StatsExtractor) -> List[StatsExtractor]:
    """
    Get all subclasses from RegressionExtractor classes tree recursively.

    Args:
        cls: root class of subclasses

    Returns:
        list of RegressionExtractor
    """
    subclasses = cls.__subclasses__()
    for subclass in subclasses:
        subclasses += get_all_subclasses(subclass)
    return subclasses
